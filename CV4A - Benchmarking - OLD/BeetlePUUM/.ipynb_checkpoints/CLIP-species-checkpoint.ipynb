{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67db37f-230e-4078-8958-184ce857f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4541e0-29d0-4cc6-adec-a8635b4e9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import open_clip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb08c79-bdbc-4901-a1c8-36e3c148f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/fs/ess/PAS2136/Hawaii-2025/beetles_intake/BeetlePUUM/1. Completed_Data/CanonBeetles.csv\"\n",
    "canon_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545e9a69-986e-4341-aebe-a3096bbaafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "canon_df[\"ImageFilePath\"] = canon_df[\"cropped_image_path\"].apply(lambda x: f\"/fs/ess/PAS2136/Hawaii-2025/beetles_intake/BeetlePUUM/CANON/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c62791d-7d2e-47e5-a875-0b4f60849cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageFilePath</th>\n",
       "      <th>ScientificName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/fs/ess/PAS2136/Hawaii-2025/beetles_intake/Bee...</td>\n",
       "      <td>Mecyclothorax konanus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/fs/ess/PAS2136/Hawaii-2025/beetles_intake/Bee...</td>\n",
       "      <td>Mecyclothorax konanus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ImageFilePath         ScientificName\n",
       "0  /fs/ess/PAS2136/Hawaii-2025/beetles_intake/Bee...  Mecyclothorax konanus\n",
       "1  /fs/ess/PAS2136/Hawaii-2025/beetles_intake/Bee...  Mecyclothorax konanus"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['ImageFilePath', 'ScientificName']\n",
    "df = canon_df[cols]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22a44b7-fd38-4b48-977d-a73b5c8e202c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms(\"ViT-B-32\", pretrained=\"openai\")\n",
    "\n",
    "tokenizer = open_clip.get_tokenizer(\"ViT-B-32\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for param in model.parameters() :\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37abf33f-1d4b-4519-ac74-bdb25b5ca259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1efb8e6-1eb0-4e2b-844e-4037232d3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clip_features(image_path):\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    image_tensor = preprocess_val(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_tensor)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return image_features.cpu().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5818bd9c-2c95-412b-8557-55ca47ca3331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature shape: (1806, 512)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack([extract_clip_features(img) for img in df[\"ImageFilePath\"]])\n",
    "\n",
    "print(f\"Extracted feature shape: {X.shape}\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(df[\"ScientificName\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fc97b0-46cd-4975-a4ca-7b69a017b32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e73c6b3-ab12-4b40-89e3-22dcaf8746c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP + MLP Accuracy: 87.29%\n"
     ]
    }
   ],
   "source": [
    "# Train MLP\n",
    "MLP = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64), \n",
    "    max_iter=200,\n",
    "    solver='adam', # lbfgs, sgd, adam\n",
    "    activation='relu', # tanh, sgd, relu\n",
    "    early_stopping = True,\n",
    "    random_state=1645\n",
    ")\n",
    "MLP.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = MLP.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"CLIP + MLP Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6519a54e-5e2b-4f56-83ef-f68d75710765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd77dd-c3fd-4c14-b0cf-35c1cf114680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a93ec-764d-48a4-a409-7609721612fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d9ff559-168b-4259-bcb6-3dd9b6bc918b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_uuid</th>\n",
       "      <th>ImageFileName</th>\n",
       "      <th>BeetleID</th>\n",
       "      <th>species</th>\n",
       "      <th>image_path</th>\n",
       "      <th>elytra_length</th>\n",
       "      <th>elytra_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98bc02b2-baef-430e-b677-fb7f496455cf</td>\n",
       "      <td>IMG_0093.JPG</td>\n",
       "      <td>BET.D20.000001</td>\n",
       "      <td>Mecyclothorax konanus</td>\n",
       "      <td>/fs/ess/PAS2136/Rayeed/BeetlePUUM/CANON/indivi...</td>\n",
       "      <td>0.638269</td>\n",
       "      <td>0.580266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2a205423-aa6f-4fcd-b366-c0311e5790e2</td>\n",
       "      <td>IMG_0093.JPG</td>\n",
       "      <td>BET.D20.000003</td>\n",
       "      <td>Mecyclothorax konanus</td>\n",
       "      <td>/fs/ess/PAS2136/Rayeed/BeetlePUUM/CANON/indivi...</td>\n",
       "      <td>0.588267</td>\n",
       "      <td>0.525040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        annotation_uuid ImageFileName        BeetleID  \\\n",
       "0  98bc02b2-baef-430e-b677-fb7f496455cf  IMG_0093.JPG  BET.D20.000001   \n",
       "1  2a205423-aa6f-4fcd-b366-c0311e5790e2  IMG_0093.JPG  BET.D20.000003   \n",
       "\n",
       "                 species                                         image_path  \\\n",
       "0  Mecyclothorax konanus  /fs/ess/PAS2136/Rayeed/BeetlePUUM/CANON/indivi...   \n",
       "1  Mecyclothorax konanus  /fs/ess/PAS2136/Rayeed/BeetlePUUM/CANON/indivi...   \n",
       "\n",
       "   elytra_length  elytra_width  \n",
       "0       0.638269      0.580266  \n",
       "1       0.588267      0.525040  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_species = df[\"species\"].unique()\n",
    "\n",
    "species_ranges = {}\n",
    "for species in unique_species:\n",
    "    base_length = np.random.uniform(0.6, 1.0)  # Base length between 0.6 and 1.0\n",
    "    base_width = np.random.uniform(0.3, 0.6)   # Base width between 0.3 and 0.6\n",
    "    \n",
    "    species_ranges[species] = {\n",
    "        \"length_range\": (base_length - 0.1, base_length + 0.1),  # Small variation\n",
    "        \"width_range\": (base_width - 0.1, base_width + 0.1)\n",
    "    }\n",
    "\n",
    "\n",
    "def assign_random_elytra(species):\n",
    "    length_range = species_ranges[species][\"length_range\"]\n",
    "    width_range = species_ranges[species][\"width_range\"]\n",
    "    \n",
    "    elytra_length = np.random.uniform(*length_range)\n",
    "    elytra_width = np.random.uniform(*width_range)\n",
    "    \n",
    "    return elytra_length, elytra_width\n",
    "    \n",
    "df[[\"elytra_length\", \"elytra_width\"]] = df[\"species\"].apply(lambda sp: assign_random_elytra(sp)).apply(pd.Series)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8bb8df-5b1a-49bd-ac5d-35c45f195710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "273be817-ec96-4aaa-8095-8f56006f0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "X_image = np.vstack([extract_clip_features(img) for img in df[\"image_path\"]])\n",
    "X_structured = df[[\"elytra_length\", \"elytra_width\"]].to_numpy()\n",
    "X_combined = np.hstack((X_image, X_structured))\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"species\"])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b938caa7-ec1f-4924-b139-4f0843fa0a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP + MLP Accuracy: 89.78%\n"
     ]
    }
   ],
   "source": [
    "# Train MLP\n",
    "MLP = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64), \n",
    "    max_iter=200,\n",
    "    solver='adam', # lbfgs, sgd, adam\n",
    "    activation='relu', # tanh, sgd, relu\n",
    "    early_stopping = True,\n",
    "    random_state=1645\n",
    ")\n",
    "MLP.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = MLP.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"CLIP + MLP Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9c21c-43cf-4f3c-9a9c-35d9eaaaa0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46002b83-8ad2-45ae-8543-a39bca716451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db0109-daed-4373-97a4-a95eb8fdcdd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21cef6-d056-410a-96a4-a0e52217ec92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ec31a-110b-4622-826d-986922c311c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
