{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469bc991-7099-4d48-bee6-fe8e43f1ac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique species: 290\n",
      "Total number of images: 63077\n",
      "df_20 shape: (2900, 4)\n",
      "df_20 shape: (5800, 4)\n",
      "WARNING: Species Drypta dentata has only 50 samples (requested 50)\n",
      "df_50 shape: (14500, 4)\n",
      "Added all 95 samples from rare species: Ophonus puncticeps\n",
      "Added all 94 samples from rare species: Miscodera arctica\n",
      "Added all 93 samples from rare species: Agonum nigrum\n",
      "Added all 92 samples from rare species: Harpalus neglectus\n",
      "Added all 91 samples from rare species: Harpalus servus\n",
      "Added all 91 samples from rare species: Acupalpus flavicollis\n",
      "Added all 90 samples from rare species: Pterostichus cristatus\n",
      "Added all 90 samples from rare species: Amara consularis\n",
      "Added all 90 samples from rare species: Bembidion testaceum\n",
      "Added all 89 samples from rare species: Laemostenus complanatus\n",
      "Added all 87 samples from rare species: Trechus fulvus\n",
      "Added all 86 samples from rare species: Carabus glabratus\n",
      "Added all 86 samples from rare species: Acupalpus brunnipes\n",
      "Added all 83 samples from rare species: Calathus ambiguus\n",
      "Added all 82 samples from rare species: Elaphropus walkerianus\n",
      "Added all 82 samples from rare species: Harpalus laevipes\n",
      "Added all 80 samples from rare species: Masoreus wetterhallii\n",
      "Added all 77 samples from rare species: Agonum ericeti\n",
      "Added all 75 samples from rare species: Asaphidion flavipes\n",
      "Added all 73 samples from rare species: Cymindis vaporariorum\n",
      "Added all 73 samples from rare species: Callistus lunatus\n",
      "Added all 72 samples from rare species: Amara curta\n",
      "Added all 71 samples from rare species: Calathus micropterus\n",
      "Added all 71 samples from rare species: Bembidion schueppelii\n",
      "Added all 71 samples from rare species: Notiophilus quadripunctatus\n",
      "Added all 69 samples from rare species: Badister dilatatus\n",
      "Added all 68 samples from rare species: Carabus clatratus\n",
      "Added all 68 samples from rare species: Poecilus kugelanni\n",
      "Added all 67 samples from rare species: Anisodactylus nemorivagus\n",
      "Added all 66 samples from rare species: Sinechostictus stomoides\n",
      "Added all 66 samples from rare species: Ophonus schaubergerianus\n",
      "Added all 66 samples from rare species: Trechus rubens\n",
      "Added all 66 samples from rare species: Elaphrus uliginosus\n",
      "Added all 65 samples from rare species: Bembidion quadripustulatum\n",
      "Added all 65 samples from rare species: Cicindela hybrida\n",
      "Added all 63 samples from rare species: Zabrus tenebrioides\n",
      "Added all 62 samples from rare species: Ophonus cordatus\n",
      "Added all 62 samples from rare species: Bembidion nigropiceum\n",
      "Added all 61 samples from rare species: Polistichus connexus\n",
      "Added all 60 samples from rare species: Licinus depressus\n",
      "Added all 60 samples from rare species: Bembidion geniculatum\n",
      "Added all 60 samples from rare species: Dyschirius obscurus\n",
      "Added all 59 samples from rare species: Stenolophus skrimshiranus\n",
      "Added all 58 samples from rare species: Pterostichus rhaeticus\n",
      "Added all 58 samples from rare species: Asaphidion stierlini\n",
      "Added all 58 samples from rare species: Dromius angustus\n",
      "Added all 58 samples from rare species: Ophonus melletii\n",
      "Added all 58 samples from rare species: Pterostichus quadrifoveolatus\n",
      "Added all 57 samples from rare species: Agonum versutum\n",
      "Added all 57 samples from rare species: Ophonus laticollis\n",
      "Added all 56 samples from rare species: Tachys micros\n",
      "Added all 54 samples from rare species: Dyschirius nitidus\n",
      "Added all 54 samples from rare species: Amara famelica\n",
      "Added all 54 samples from rare species: Pterostichus aethiops\n",
      "Added all 54 samples from rare species: Harpalus tenebrosus\n",
      "Added all 54 samples from rare species: Patrobus septentrionis\n",
      "Added all 53 samples from rare species: Blemus discus\n",
      "Added all 52 samples from rare species: Cymindis axillaris\n",
      "Added all 52 samples from rare species: Paradromius longiceps\n",
      "Added all 52 samples from rare species: Panagaeus cruxmajor\n",
      "Added all 50 samples from rare species: Drypta dentata\n",
      "Taking 112 samples from each of the 229 common species\n",
      "Still need 182 more samples to reach target\n",
      "df_30k shape: (30000, 4)\n",
      "df_full shape: (63077, 4)\n",
      "\n",
      "20 per species Species Distribution:\n",
      "- Min samples per species: 20\n",
      "- Max samples per species: 20\n",
      "- Mean samples per species: 20.00\n",
      "\n",
      "50 per species Species Distribution:\n",
      "- Min samples per species: 50\n",
      "- Max samples per species: 50\n",
      "- Mean samples per species: 50.00\n",
      "\n",
      "30K dataset Species Distribution:\n",
      "- Min samples per species: 50\n",
      "- Max samples per species: 117\n",
      "- Mean samples per species: 103.45\n",
      "\n",
      "Full dataset Species Distribution:\n",
      "- Min samples per species: 50\n",
      "- Max samples per species: 888\n",
      "- Mean samples per species: 217.51\n",
      "\n",
      "Overlap Statistics:\n",
      "Images in both df_20 and df_50: 5800\n",
      "Images in both df_20 and df_30k: 5800\n",
      "Images in both df_50 and df_30k: 14500\n",
      "\n",
      "Probing subsets created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "file_dir = \"/users/PAS2136/rayees/CV4A - Domain Adaptation\"\n",
    "file_path = f\"{file_dir}/DataFinalized.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[df[\"Dataset\"] == \"BritishCarabids\"]\n",
    "\n",
    "\n",
    "species_counts = df['ScientificName'].value_counts()\n",
    "print(f\"Total number of unique species: {len(species_counts)}\")\n",
    "print(f\"Total number of images: {len(df)}\")\n",
    "\n",
    "\n",
    "outdir = \"/users/PAS2136/rayees/CV4A - Efficient Probing\"\n",
    "output_dir = Path(outdir) / \"ProbingSubsets\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def create_balanced_sample(df, samples_per_species, species_counts):\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    for species in species_counts.index:\n",
    "        species_df = df[df['ScientificName'] == species]\n",
    "        available = len(species_df)\n",
    "        \n",
    "        # Take all available if less than requested, otherwise sample\n",
    "        if available <= samples_per_species:\n",
    "            sampled = species_df\n",
    "            print(f\"WARNING: Species {species} has only {available} samples (requested {samples_per_species})\")\n",
    "        else:\n",
    "            sampled = species_df.sample(samples_per_species, random_state=42)\n",
    "            \n",
    "        result_df = pd.concat([result_df, sampled])\n",
    "    \n",
    "    return result_df\n",
    "    \n",
    "\n",
    "df_20 = create_balanced_sample(df, 10, species_counts)\n",
    "print(f\"df_20 shape: {df_20.shape}\")\n",
    "df_20.to_csv(output_dir / \"probing_10_per_species.csv\", index=False)\n",
    "\n",
    "df_20 = create_balanced_sample(df, 20, species_counts)\n",
    "print(f\"df_20 shape: {df_20.shape}\")\n",
    "df_20.to_csv(output_dir / \"probing_20_per_species.csv\", index=False)\n",
    "\n",
    "\n",
    "df_50 = create_balanced_sample(df, 50, species_counts)\n",
    "print(f\"df_50 shape: {df_50.shape}\")\n",
    "df_50.to_csv(output_dir / \"probing_50_per_species.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "def create_30k_dataset(df, species_counts, target_size=30000):\n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    remaining_species = []\n",
    "    \n",
    "    for species, count in species_counts.items():\n",
    "        if count < 100:\n",
    "            species_df = df[df['ScientificName'] == species]\n",
    "            result_df = pd.concat([result_df, species_df])\n",
    "            print(f\"Added all {count} samples from rare species: {species}\")\n",
    "        else:\n",
    "            remaining_species.append(species)\n",
    "    \n",
    "    remaining_needed = target_size - len(result_df)\n",
    "    \n",
    "    if remaining_needed <= 0:\n",
    "        print(f\"WARNING: Already exceeded target size with rare species alone: {len(result_df)}\")\n",
    "        return result_df\n",
    "\n",
    "    samples_per_species = remaining_needed // len(remaining_species)\n",
    "    print(f\"Taking {samples_per_species} samples from each of the {len(remaining_species)} common species\")\n",
    "\n",
    "    for species in remaining_species:\n",
    "        species_df = df[df['ScientificName'] == species]\n",
    "        sampled = species_df.sample(min(samples_per_species, len(species_df)), random_state=42)\n",
    "        result_df = pd.concat([result_df, sampled])\n",
    "    \n",
    "    if len(result_df) < target_size:\n",
    "        still_needed = target_size - len(result_df)\n",
    "        print(f\"Still need {still_needed} more samples to reach target\")\n",
    "        \n",
    "        extra_capacity_species = []\n",
    "        for species in remaining_species:\n",
    "            species_count = species_counts[species]\n",
    "            used_count = len(result_df[result_df['ScientificName'] == species])\n",
    "            if species_count > used_count:\n",
    "                extra_capacity_species.append((species, species_count - used_count))\n",
    "        \n",
    "        if extra_capacity_species:\n",
    "            extra_capacity_species.sort(key=lambda x: x[1], reverse=True)\n",
    "            total_extra_capacity = sum(capacity for _, capacity in extra_capacity_species)\n",
    "            for species, capacity in extra_capacity_species:\n",
    "                if still_needed <= 0:\n",
    "                    break\n",
    "                    \n",
    "                to_take = min(int(np.ceil(capacity * still_needed / total_extra_capacity)), capacity, still_needed)\n",
    "                if to_take > 0:\n",
    "                    species_df = df[df['ScientificName'] == species]\n",
    "                    already_used = result_df[result_df['ScientificName'] == species].index\n",
    "                    available = species_df[~species_df.index.isin(already_used)]\n",
    "                    \n",
    "                    if len(available) >= to_take:\n",
    "                        additional = available.sample(to_take, random_state=42)\n",
    "                        result_df = pd.concat([result_df, additional])\n",
    "                        still_needed -= to_take\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_30k = create_30k_dataset(df, species_counts)\n",
    "print(f\"df_30k shape: {df_30k.shape}\")\n",
    "df_30k.to_csv(output_dir / \"probing_30k_images.csv\", index=False)\n",
    "\n",
    "\n",
    "df_full = df.copy()\n",
    "print(f\"df_full shape: {df_full.shape}\")\n",
    "df_full.to_csv(output_dir / \"probing_full_dataset.csv\", index=False)\n",
    "\n",
    "\n",
    "def print_species_distribution(subset_df, name):\n",
    "    subset_counts = subset_df['ScientificName'].value_counts()\n",
    "    print(f\"\\n{name} Species Distribution:\")\n",
    "    print(f\"- Min samples per species: {subset_counts.min()}\")\n",
    "    print(f\"- Max samples per species: {subset_counts.max()}\")\n",
    "    print(f\"- Mean samples per species: {subset_counts.mean():.2f}\")\n",
    "\n",
    "print_species_distribution(df_20, \"20 per species\")\n",
    "print_species_distribution(df_50, \"50 per species\") \n",
    "print_species_distribution(df_30k, \"30K dataset\")\n",
    "print_species_distribution(df_full, \"Full dataset\")\n",
    "\n",
    "\n",
    "print(\"\\nOverlap Statistics:\")\n",
    "print(f\"Images in both df_20 and df_50: {len(set(df_20.index).intersection(set(df_50.index)))}\")\n",
    "print(f\"Images in both df_20 and df_30k: {len(set(df_20.index).intersection(set(df_30k.index)))}\")\n",
    "print(f\"Images in both df_50 and df_30k: {len(set(df_50.index).intersection(set(df_30k.index)))}\")\n",
    "\n",
    "print(\"\\nProbing subsets created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a3adc7-fdcd-4ebf-8af5-e77198d02845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ratio-preserving sample of size 2900\n",
      "\n",
      "Probing 2900 Ratio Distribution:\n",
      "- Number of species: 290\n",
      "- Min samples per species: 2\n",
      "- Max samples per species: 41\n",
      "- Mean samples per species: 10.00\n",
      "- Correlation with original distribution: 0.9989\n",
      "- Top 5 species in sample:\n",
      "  Notiophilus biguttatus: 41 samples (4.62% of original)\n",
      "  Bembidion tetracolum: 40 samples (4.65% of original)\n",
      "  Pterostichus strenuus: 38 samples (4.65% of original)\n",
      "  Ophonus rufibarbis: 33 samples (4.59% of original)\n",
      "  Bembidion lampros: 32 samples (4.66% of original)\n",
      "Created ratio-preserving sample of size 5800\n",
      "\n",
      "Probing 5800 Ratio Distribution:\n",
      "- Number of species: 290\n",
      "- Min samples per species: 5\n",
      "- Max samples per species: 82\n",
      "- Mean samples per species: 20.00\n",
      "- Correlation with original distribution: 0.9998\n",
      "- Top 5 species in sample:\n",
      "  Notiophilus biguttatus: 82 samples (9.23% of original)\n",
      "  Bembidion tetracolum: 79 samples (9.18% of original)\n",
      "  Pterostichus strenuus: 75 samples (9.17% of original)\n",
      "  Ophonus rufibarbis: 66 samples (9.18% of original)\n",
      "  Bembidion lampros: 63 samples (9.18% of original)\n",
      "Created ratio-preserving sample of size 14500\n",
      "\n",
      "Probing 14500 Ratio Distribution:\n",
      "- Number of species: 290\n",
      "- Min samples per species: 11\n",
      "- Max samples per species: 204\n",
      "- Mean samples per species: 50.00\n",
      "- Correlation with original distribution: 1.0000\n",
      "- Top 5 species in sample:\n",
      "  Notiophilus biguttatus: 204 samples (22.97% of original)\n",
      "  Bembidion tetracolum: 198 samples (23.00% of original)\n",
      "  Pterostichus strenuus: 188 samples (22.98% of original)\n",
      "  Ophonus rufibarbis: 165 samples (22.95% of original)\n",
      "  Bembidion lampros: 158 samples (23.03% of original)\n",
      "\n",
      "Ratio-preserving probing subsets created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Function to create ratio-preserving samples\n",
    "def create_ratio_preserving_sample(df, target_size, species_counts):\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    # Calculate sampling fraction\n",
    "    sampling_fraction = target_size / len(df)\n",
    "    \n",
    "    # For each species, take samples proportional to their original frequency\n",
    "    for species, count in species_counts.items():\n",
    "        species_df = df[df['ScientificName'] == species]\n",
    "        \n",
    "        # Calculate how many samples to take based on original ratio\n",
    "        samples_to_take = max(1, int(np.round(count * sampling_fraction)))\n",
    "        \n",
    "        # Ensure we don't take more samples than available\n",
    "        samples_to_take = min(samples_to_take, count)\n",
    "        \n",
    "        # Sample from this species\n",
    "        sampled = species_df.sample(samples_to_take, random_state=42)\n",
    "        result_df = pd.concat([result_df, sampled])\n",
    "    \n",
    "    # Handle any small discrepancy in final size due to rounding\n",
    "    if len(result_df) > target_size:\n",
    "        # Remove random samples to reach target size\n",
    "        result_df = result_df.sample(target_size, random_state=42)\n",
    "    elif len(result_df) < target_size:\n",
    "        # Add more samples from species with remaining capacity\n",
    "        remaining_needed = target_size - len(result_df)\n",
    "        \n",
    "        # Find which species have remaining samples\n",
    "        additional_capacity = {}\n",
    "        for species in species_counts.index:\n",
    "            used = len(result_df[result_df['ScientificName'] == species])\n",
    "            available = species_counts[species] - used\n",
    "            if available > 0:\n",
    "                additional_capacity[species] = available\n",
    "        \n",
    "        # Sort species by remaining capacity, weighted by original distribution\n",
    "        weighted_capacity = {sp: (ct/species_counts[sp]) * species_counts[sp]/total_images \n",
    "                             for sp, ct in additional_capacity.items()}\n",
    "        sorted_species = sorted(weighted_capacity.keys(), \n",
    "                                key=lambda s: weighted_capacity[s], \n",
    "                                reverse=True)\n",
    "        \n",
    "        # Add samples until we reach target size\n",
    "        for species in sorted_species:\n",
    "            if remaining_needed <= 0:\n",
    "                break\n",
    "                \n",
    "            species_df = df[df['ScientificName'] == species]\n",
    "            already_used = result_df[result_df['ScientificName'] == species].index\n",
    "            available = species_df[~species_df.index.isin(already_used)]\n",
    "            \n",
    "            to_take = min(1, len(available), remaining_needed)\n",
    "            if to_take > 0:\n",
    "                additional = available.sample(to_take, random_state=42)\n",
    "                result_df = pd.concat([result_df, additional])\n",
    "                remaining_needed -= to_take\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Create the ratio-preserving samples\n",
    "target_sizes = [2900, 5800, 14500]\n",
    "for size in target_sizes:\n",
    "    ratio_df = create_ratio_preserving_sample(df, size, species_counts)\n",
    "    print(f\"Created ratio-preserving sample of size {len(ratio_df)}\")\n",
    "    ratio_df.to_csv(output_dir / f\"probing_{size}_ratio.csv\", index=False)\n",
    "    \n",
    "    # Print distribution statistics\n",
    "    ratio_counts = ratio_df['ScientificName'].value_counts()\n",
    "    print(f\"\\nProbing {size} Ratio Distribution:\")\n",
    "    print(f\"- Number of species: {len(ratio_counts)}\")\n",
    "    print(f\"- Min samples per species: {ratio_counts.min()}\")\n",
    "    print(f\"- Max samples per species: {ratio_counts.max()}\")\n",
    "    print(f\"- Mean samples per species: {ratio_counts.mean():.2f}\")\n",
    "    \n",
    "    # Verify ratio preservation\n",
    "    original_proportions = species_counts / species_counts.sum()\n",
    "    sample_proportions = ratio_counts / ratio_counts.sum()\n",
    "    \n",
    "    # Calculate correlation between original and sample proportions\n",
    "    correlation = original_proportions.corr(sample_proportions)\n",
    "    print(f\"- Correlation with original distribution: {correlation:.4f}\")\n",
    "    \n",
    "    # Show top 5 species in this sample\n",
    "    print(\"- Top 5 species in sample:\")\n",
    "    for species, count in ratio_counts.head(5).items():\n",
    "        original = species_counts[species]\n",
    "        print(f\"  {species}: {count} samples ({count/original:.2%} of original)\")\n",
    "\n",
    "print(\"\\nRatio-preserving probing subsets created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1685a-6fbc-489c-8c64-4365d20f4ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f54b40-262b-455a-ad22-38a39d983794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
