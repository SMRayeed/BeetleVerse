{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9693b544-22dc-41b9-bd6e-581eb3c8e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d304ca9d-f60f-44c7-8b99-9101a1a06944",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"google/siglip-base-patch16-224\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name).to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25d6005-09a1-4e8f-98a6-825689ecf191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.818737/ipykernel_2590302/1676424945.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ImageFilePath'] = \"/fs/ess/PAS2136/Rayeed/Carabids-100K-V2/\" + df['ImageFilePath']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageFilePath</th>\n",
       "      <th>ScientificName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/fs/ess/PAS2136/Rayeed/Carabids-100K-V2/Insect...</td>\n",
       "      <td>Cicindela sexguttata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/fs/ess/PAS2136/Rayeed/Carabids-100K-V2/Insect...</td>\n",
       "      <td>Cicindela sexguttata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ImageFilePath        ScientificName\n",
       "0  /fs/ess/PAS2136/Rayeed/Carabids-100K-V2/Insect...  Cicindela sexguttata\n",
       "1  /fs/ess/PAS2136/Rayeed/Carabids-100K-V2/Insect...  Cicindela sexguttata"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allCarabids = pd.read_csv(\"/fs/ess/PAS2136/Rayeed/Carabids-100K-V2/AllCarabids.csv\", sep=\"\\t\")\n",
    "df_insect1M = df_allCarabids[df_allCarabids[\"filepath\"].str.startswith(\"Insect-1M\")].copy()\n",
    "df_insect1M.rename(columns={\"filepath\": \"ImageFilePath\", \"class\": \"ScientificName\"}, inplace=True)\n",
    "cols = ['ImageFilePath', 'ScientificName']\n",
    "df = df_insect1M[cols]\n",
    "df['ImageFilePath'] = \"/fs/ess/PAS2136/Rayeed/Carabids-100K-V2/\" + df['ImageFilePath']\n",
    "df = df.dropna()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b99cb76-2ba7-4dbe-8eb4-2ee3588d86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path) :\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model.get_image_features(pixel_values=inputs[\"pixel_values\"])\n",
    "    \n",
    "    return features.cpu().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2313e6-cf4e-48f1-b571-b2b100ed8091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 13178/20278 [03:52<01:43, 68.39it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([extract_features(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageFilePath\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n\u001b[1;32m      3\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScientificName\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageFilePath\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n\u001b[1;32m      3\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScientificName\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      8\u001b[0m     features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_image_features(pixel_values\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = np.vstack([extract_features(img) for img in tqdm(df[\"ImageFilePath\"])])\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(df[\"ScientificName\"])\n",
    "\n",
    "df_indices = df.index \n",
    "\n",
    "X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(X, y, df_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "test_df = df.loc[test_idx].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0381a92-4faa-4c6a-9d27-f736a49e0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99\n",
    "\n",
    "models = {\n",
    "    \"NaiveBayes\": GaussianNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=100),\n",
    "    \"NearestNeighbor\": KNeighborsClassifier(n_neighbors=5), \n",
    "    \"MLP_Baseline\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=200, random_state=seed)\n",
    "}\n",
    "\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    predictions[name] = preds\n",
    "    \n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    prec = precision_score(y_test, preds, average=\"weighted\")\n",
    "    rec = recall_score(y_test, preds, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, preds, average=\"weighted\")\n",
    "    bal_acc = balanced_accuracy_score(y_test, preds)\n",
    "    mcc = matthews_corrcoef(y_test, preds)\n",
    "    \n",
    "    metrics[name] = {\"Model\": name, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1-Score\": f1, \"Balanced Acc\": bal_acc, \"MCC\": mcc}\n",
    "    print(f\"{name:<25} | Acc: {acc:.2%} | Prec: {prec:.2%} | Rec: {rec:.2%} | F1: {f1:.2%} | Bal Acc: {bal_acc:.2%} | MCC: {mcc:.4f}\")\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436101d-307d-405f-8c0f-ca33b014add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.assign(**{f\"Pred_{name}\": le.inverse_transform(pred) for name, pred in predictions.items()})\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1015575-2991-44b6-b748-6c2993af6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d624d-dd05-4e2c-92b1-ec08ab1c12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"/users/PAS2136/rayees/CV4A - Benchmarking/Insect1M_dropna/10.SigLIP-linear-probing-species.csv\", index=False)\n",
    "metrics_df.to_csv(\"/users/PAS2136/rayees/CV4A - Benchmarking/Insect1M_dropna/10.SigLIP-linear-probing-species-metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2179e5a-001d-4da4-b603-4c57878f5e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
